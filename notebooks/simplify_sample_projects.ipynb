{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script will remove not used functions from sample projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibiscp/GitHub/logspace/alfred/modules/refinery-gateway/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "from controller.transfer import project_transfer_manager as pm\n",
    "import umap\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "path = \"../sample_projects/\"\n",
    "\n",
    "# List files ending with .zip\n",
    "files = [f for f in os.listdir(path) if f.endswith(\".zip\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = ['clickbait.zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reduced embeddings\n",
    "trans = umap.UMAP(n_neighbors=10,\n",
    "        min_dist=0.1,\n",
    "        n_components=2,\n",
    "        metric=\"euclidean\",\n",
    "        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # Extract zip file\n",
    "    data = pm.extract_first_zip_data(f\"{path}{file}\")\n",
    "\n",
    "    # for key in data.keys():\n",
    "    #     print(key)\n",
    "    \n",
    "    # Remove labeling tasks\n",
    "    # Labeling Tasks\n",
    "    lt_ids = [lt['id'] for lt in data['labeling_tasks_data'] if lt['task_type'] != 'MULTICLASS_CLASSIFICATION']\n",
    "\n",
    "    # Labeling task labels\n",
    "    ltl_ids = [ltl['id'] for ltl in data['labeling_task_labels_data'] if ltl['labeling_task_id'] in lt_ids]\n",
    "\n",
    "    # Information Source\n",
    "    is_ids = [is_['id'] for is_ in data['information_sources_data'] if is_['type'] != 'ACTIVE_LEARNING']\n",
    "\n",
    "    # Information Source Payload\n",
    "    isp_ids = [isp['id'] for isp in data['information_source_payloads_data'] if isp['source_id'] in is_ids]\n",
    "\n",
    "    # Information Source Statistics\n",
    "    iss_ids = [iss['id'] for iss in data['information_source_statistics_data'] if iss['source_id'] in is_ids or iss['labeling_task_label_id'] in ltl_ids]\n",
    "\n",
    "    # Record label associations\n",
    "    rla_ids = [rla['id'] for rla in data['record_label_associations_data'] if rla['source_id'] in is_ids or rla['labeling_task_label_id'] in ltl_ids]\n",
    "\n",
    "    # Record label association token\n",
    "    rlat = [rlat for rlat in data['record_label_association_tokens_data'] if rlat['record_label_association_id'] not in rla_ids]\n",
    "    \n",
    "\n",
    "    # Remove everything\n",
    "    data['record_label_association_tokens_data'] = rlat\n",
    "    data['record_label_associations_data'] = [rla for rla in data['record_label_associations_data'] if rla['id'] not in rla_ids]\n",
    "    data['information_source_statistics_data'] = [iss for iss in data['information_source_statistics_data'] if iss['id'] not in iss_ids]\n",
    "    data['information_source_payloads_data'] = [isp for isp in data['information_source_payloads_data'] if isp['id'] not in isp_ids]\n",
    "    data['information_sources_data'] = [is_ for is_ in data['information_sources_data'] if is_['id'] not in is_ids]\n",
    "    data['labeling_task_labels_data'] = [ltl for ltl in data['labeling_task_labels_data'] if ltl['id'] not in ltl_ids]\n",
    "    data['labeling_tasks_data'] = [lt for lt in data['labeling_tasks_data'] if lt['id'] not in lt_ids]\n",
    "\n",
    "    if data[\"embedding_tensors_data\"]:\n",
    "        embedding_vector = np.array([e['data'] for e in data[\"embedding_tensors_data\"]])\n",
    "        data_reduced = trans.fit_transform(embedding_vector)\n",
    "\n",
    "        for i, e in enumerate(data[\"embedding_tensors_data\"]):\n",
    "            e['data_reduced'] = data_reduced[i].tolist()\n",
    "\n",
    "    # Save file\n",
    "    with ZipFile(f\"{path}changed/{file}\", 'w') as myzip:\n",
    "        with myzip.open(\"config.json\", \"w\") as c:\n",
    "            c.write(json.dumps(data).encode(\"utf-8\"))\n",
    "\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fec8f8e63dfa9d9bb605eaa8697ff2153839b94214e67b8fc923af9f9f5ea415"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
